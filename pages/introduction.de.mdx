# Einleitung

Prompt-Engineering ist eine relativ neue Disziplin, die sich mit der Entwicklung und Optimierung von Eingabeaufforderungen (Prompts) beschäftigt, um Sprachmodelle (LMs) effizient für eine breite Palette von Anwendungen und Forschungsthemen zu nutzen. Kompetenzen im Prompt-Engineering helfen dabei, die Fähigkeiten und Grenzen von großen Sprachmodellen (LLMs) besser zu verstehen. Forscher verwenden Prompt-Engineering, um die Fähigkeiten von LLMs bei einer Vielzahl von gängigen und komplexen Aufgaben wie Fragebeantwortung und arithmetisches Denken zu verbessern. Entwickler setzen Prompt-Engineering ein, um robuste und effektive Techniken für die Interaktion mit LLMs und anderen Werkzeugen zu gestalten.

Dieser Leitfaden behandelt die Grundlagen von Prompts, um eine grobe Idee davon zu vermitteln, wie Sie Prompts verwenden können, um mit LLMs zu interagieren und sie zu instruieren.

Alle Beispiele sind mit `gpt-3.5-turbo` unter Verwendung von [OpenAIs Playground](https://platform.openai.com/playground) getestet, sofern nicht anders angegeben. Das Modell verwendet die Standardeinstellungen, d.h. `temperature=1` und `top_p=1`. Die Prompts sollten auch mit anderen Modellen funktionieren, welche ähnliche Fähigkeiten wie `gpt-3.5-turbo` haben, jedoch könnten deren Antworten abweichen.
