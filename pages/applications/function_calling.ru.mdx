# Вызов функций с помощью LLM

import {Cards, Card} from 'nextra-theme-docs'
import {CodeIcon} from 'components/icons'

## Начало работы с вызовом функций

Вызов функций — это возможность надежно подключать LLM к внешним инструментам, чтобы обеспечить эффективное использование инструментов и взаимодействие с внешними API.

LLM, такие как GPT-4 и GPT-3.5, были точно настроены, чтобы определять, когда необходимо вызвать функцию, а затем выводить JSON, содержащий аргументы для вызова функции. Функции, вызываемые при вызове, будут действовать как инструменты в вашем ИИ приложении, и вы можете определить более одной функции в одном запросе.

Вызов функций — это важная возможность для создания чат-ботов или агентов на базе LLM, которым необходимо получать контекст для LLM или взаимодействовать с внешними инструментами путем преобразования естественного языка в вызовы API.

Вызов функций позволяет разработчикам создавать:

- диалоговые агенты, которые могут эффективно использовать внешние инструменты для ответов на вопросы. Например, запрос «Какая погода в Белизе?» будет преобразовано в вызов функции, такой как `get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')`
- Решения на базе LLM для извлечения и маркировки данных (например, извлечение имен людей из статьи в Википедии).)
- приложения, которые могут помочь преобразовать естественный язык в вызовы API или запросы к базе данных.
- диалоговые механизмы поиска знаний, которые взаимодействуют с базой знаний

В этом руководстве мы покажем, как предлагать моделям, таким как GPT-4, и моделям с открытым исходным кодом, выполнять вызов функций для различных сценариев использования.
